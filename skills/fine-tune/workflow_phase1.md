# Phase 1: æº–å‚™ã¨åˆ†æ

æœ€é©åŒ–ã®æ–¹å‘æ€§ã‚’æ˜ç¢ºã«ã—ã€æ”¹å–„å¯¾è±¡ã‚’ç‰¹å®šã™ã‚‹æº–å‚™ãƒ•ã‚§ãƒ¼ã‚ºã€‚

**æ‰€è¦æ™‚é–“**: 30åˆ†-1æ™‚é–“

**ğŸ“‹ é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“](./workflow.md) | [å®Ÿè·µä¾‹](./examples.md)

---

## Phase 1: æº–å‚™ã¨åˆ†æ

### Step 1: fine-tune.md ã®èª­ã¿è¾¼ã¿ã¨ç†è§£

**ç›®çš„**: æœ€é©åŒ–ã®æ–¹å‘æ€§ã‚’æ˜ç¢ºã«ã™ã‚‹

**å®Ÿè¡Œå†…å®¹**:
```python
# .langgraph-master/fine-tune.md ã‚’èª­ã¿è¾¼ã‚€
file_path = ".langgraph-master/fine-tune.md"
with open(file_path, "r") as f:
    fine_tune_spec = f.read()

# ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡º
# - æœ€é©åŒ–ç›®æ¨™ï¼ˆaccuracy, latency, cost ãªã©ï¼‰
# - è©•ä¾¡æ–¹æ³•ï¼ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã€è©•ä¾¡æŒ‡æ¨™ã€è¨ˆç®—æ–¹æ³•ï¼‰
# - åˆæ ¼åŸºæº–ï¼ˆå„æŒ‡æ¨™ã®ç›®æ¨™å€¤ï¼‰
# - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å ´æ‰€
```

**fine-tune.md ã®å…¸å‹çš„ãªæ§‹é€ **:
```markdown
# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç›®æ¨™

## æœ€é©åŒ–ç›®æ¨™
- **Accuracy**: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³ã®åˆ†é¡ç²¾åº¦ã‚’90%ä»¥ä¸Šã«å‘ä¸Š
- **Latency**: å¿œç­”æ™‚é–“ã‚’2.0ç§’ä»¥ä¸‹ã«çŸ­ç¸®
- **Cost**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆã‚’$0.010ä»¥ä¸‹ã«å‰Šæ¸›

## è©•ä¾¡æ–¹æ³•
- **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹**: tests/evaluation/test_cases.json (20ã‚±ãƒ¼ã‚¹)
- **å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰**: uv run python -m src.evaluate
- **è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: tests/evaluation/evaluator.py

## è©•ä¾¡æŒ‡æ¨™

### Accuracy
- è¨ˆç®—æ–¹æ³•: (æ­£è§£æ•° / ç·ã‚±ãƒ¼ã‚¹æ•°) Ã— 100
- ç›®æ¨™å€¤: 90%ä»¥ä¸Š

### Latency
- è¨ˆç®—æ–¹æ³•: å„å®Ÿè¡Œã®å¹³å‡æ™‚é–“
- ç›®æ¨™å€¤: 2.0ç§’ä»¥ä¸‹

### Cost
- è¨ˆç®—æ–¹æ³•: ç·API ã‚³ã‚¹ãƒˆ / ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
- ç›®æ¨™å€¤: $0.010ä»¥ä¸‹

## åˆæ ¼åŸºæº–
ã™ã¹ã¦ã®è©•ä¾¡æŒ‡æ¨™ãŒç›®æ¨™å€¤ã‚’é”æˆã™ã‚‹ã“ã¨
```

### Step 2: Serena MCP ã§ã®æœ€é©åŒ–å¯¾è±¡ç‰¹å®š

**ç›®çš„**: LLM ã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã‚’ç¶²ç¾…çš„ã«ç‰¹å®š

**å®Ÿè¡Œæ‰‹é †**:

1. **LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æ¤œç´¢**
```python
# Serena MCP: find_symbol ã‚’ä½¿ç”¨
# ChatAnthropic, ChatOpenAI, ChatGoogleGenerativeAI ãªã©ã‚’æ¤œç´¢

patterns = [
    "ChatAnthropic",
    "ChatOpenAI",
    "ChatGoogleGenerativeAI",
    "ChatVertexAI"
]

llm_usages = []
for pattern in patterns:
    results = serena.find_symbol(
        name_path=pattern,
        substring_matching=True,
        include_body=False
    )
    llm_usages.extend(results)
```

2. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ç®‡æ‰€ã®ç‰¹å®š**
```python
# å„ LLM å‘¼ã³å‡ºã—ã«ã¤ã„ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã©ã†æ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹ã‹èª¿æŸ»
for usage in llm_usages:
    # find_referencing_symbols ã§å‘¨è¾ºã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    context = serena.find_referencing_symbols(
        name_path=usage.name,
        relative_path=usage.file_path
    )

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç‰¹å®š
    # - ChatPromptTemplate ã®ä½¿ç”¨
    # - SystemMessage, HumanMessage ã®å®šç¾©
    # - f-string ã‚„ format() ã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
```

3. **ãƒãƒ¼ãƒ‰ã”ã¨ã®åˆ†æ**
```python
# å„ãƒãƒ¼ãƒ‰é–¢æ•°å†…ã§ã® LLM ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
# - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ˜ç¢ºæ€§
# - Few-shot examples ã®æœ‰ç„¡
# - å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ§‹é€ åŒ–
# - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆtemperature, max_tokens ãªã©ï¼‰
```

**å‡ºåŠ›ä¾‹**:
```markdown
## LLM å‘¼ã³å‡ºã—ç®‡æ‰€ã®åˆ†æ

### 1. analyze_intent ãƒãƒ¼ãƒ‰
- **ãƒ•ã‚¡ã‚¤ãƒ«**: src/nodes/analyzer.py
- **è¡Œç•ªå·**: 25-45
- **LLM**: ChatAnthropic(model="claude-3-5-sonnet-20241022")
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ **:
  ```python
  SystemMessage: "You are an intent analyzer..."
  HumanMessage: f"Analyze: {user_input}"
  ```
- **æ”¹å–„å¯èƒ½æ€§**: â­â­â­â­â­ (é«˜)
  - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæ›–æ˜§ï¼ˆ"Analyze" ã®åŸºæº–ãŒä¸æ˜ç¢ºï¼‰
  - Few-shot examples ãªã—
  - å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒè‡ªç”±ãƒ†ã‚­ã‚¹ãƒˆ
- **æ¨å®šæ”¹å–„åŠ¹æœ**: Accuracy +10-15%

### 2. generate_response ãƒãƒ¼ãƒ‰
- **ãƒ•ã‚¡ã‚¤ãƒ«**: src/nodes/generator.py
- **è¡Œç•ªå·**: 45-68
- **LLM**: ChatAnthropic(model="claude-3-5-sonnet-20241022")
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ **:
  ```python
  ChatPromptTemplate.from_messages([
      ("system", "Generate helpful response..."),
      ("human", "{context}\n\nQuestion: {question}")
  ])
  ```
- **æ”¹å–„å¯èƒ½æ€§**: â­â­â­ (ä¸­)
  - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æ§‹é€ çš„ã ãŒã€ç°¡æ½”æ€§ã®æŒ‡ç¤ºãªã—
  - max_tokens åˆ¶é™ãªã— â†’ å†—é•·ãªå‡ºåŠ›ã®å¯èƒ½æ€§
- **æ¨å®šæ”¹å–„åŠ¹æœ**: Latency -0.3-0.5s, Cost -20-30%
```

### Step 3: æœ€é©åŒ–ç®‡æ‰€ãƒªã‚¹ãƒˆã®ä½œæˆ

**ç›®çš„**: æ”¹å–„ã®å„ªå…ˆé †ä½ã‚’æ±ºå®šã™ã‚‹ãŸã‚ã®æƒ…å ±æ•´ç†

**ãƒªã‚¹ãƒˆä½œæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**:
```markdown
# æœ€é©åŒ–ç®‡æ‰€ãƒªã‚¹ãƒˆ

## ãƒãƒ¼ãƒ‰: analyze_intent

### åŸºæœ¬æƒ…å ±
- **ãƒ•ã‚¡ã‚¤ãƒ«**: src/nodes/analyzer.py:25-45
- **å½¹å‰²**: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®æ„å›³ã‚’åˆ†é¡
- **LLM ãƒ¢ãƒ‡ãƒ«**: claude-3-5-sonnet-20241022
- **ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: temperature=1.0, max_tokens=default

### ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
```python
SystemMessage(content="You are an intent analyzer. Analyze user input.")
HumanMessage(content=f"Analyze: {user_input}")
```

### å•é¡Œç‚¹
1. **æ›–æ˜§ãªæŒ‡ç¤º**: "Analyze" ã®å…·ä½“çš„ãªåŸºæº–ãŒä¸æ˜
2. **Few-shot ãªã—**: æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹ãŒãªã„
3. **å‡ºåŠ›å½¢å¼æœªå®šç¾©**: è‡ªç”±ãƒ†ã‚­ã‚¹ãƒˆã§æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„
4. **é«˜ temperature**: 1.0 ã¯åˆ†é¡ã‚¿ã‚¹ã‚¯ã«ã¯é«˜ã™ãã‚‹

### æ”¹å–„æ¡ˆ
1. å…·ä½“çš„ãªåˆ†é¡ã‚«ãƒ†ã‚´ãƒªã‚’æ˜è¨˜
2. Few-shot examples ã‚’ 3-5 å€‹è¿½åŠ 
3. JSON å‡ºåŠ›å½¢å¼ã‚’æŒ‡å®š
4. temperature ã‚’ 0.3-0.5 ã«ä¸‹ã’ã‚‹

### æ¨å®šæ”¹å–„åŠ¹æœ
- **Accuracy**: +10-15% (ç¾çŠ¶ã®èª¤åˆ†é¡20% â†’ 5-10%)
- **Latency**: Â±0 (å¤‰åŒ–ãªã—)
- **Cost**: Â±0 (å¤‰åŒ–ãªã—)

### å„ªå…ˆåº¦
â­â­â­â­â­ (æœ€å„ªå…ˆ) - accuracy å‘ä¸Šã¸ã®ç›´æ¥çš„ãªå½±éŸ¿

---

## ãƒãƒ¼ãƒ‰: generate_response

### åŸºæœ¬æƒ…å ±
- **ãƒ•ã‚¡ã‚¤ãƒ«**: src/nodes/generator.py:45-68
- **å½¹å‰²**: æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘å¿œç­”ã‚’ç”Ÿæˆ
- **LLM ãƒ¢ãƒ‡ãƒ«**: claude-3-5-sonnet-20241022
- **ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: temperature=0.7, max_tokens=default

### ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
```python
ChatPromptTemplate.from_messages([
    ("system", "Generate helpful response based on context."),
    ("human", "{context}\n\nQuestion: {question}")
])
```

### å•é¡Œç‚¹
1. **å†—é•·æ€§åˆ¶å¾¡ãªã—**: ç°¡æ½”æ€§ã®æŒ‡ç¤ºãŒãªã„
2. **max_tokens æœªè¨­å®š**: ä¸å¿…è¦ã«é•·ã„å‡ºåŠ›ã®å¯èƒ½æ€§
3. **å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«æœªå®šç¾©**: ãƒˆãƒ¼ãƒ³ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã®æŒ‡å®šãŒãªã„

### æ”¹å–„æ¡ˆ
1. "ç°¡æ½”ã«" "2-3æ–‡ã§" ãªã©ã®é•·ã•æŒ‡ç¤ºã‚’è¿½åŠ 
2. max_tokens ã‚’ 500 ã«åˆ¶é™
3. å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ˜ç¢ºåŒ–ï¼ˆ"è¦ªã—ã¿ã‚„ã™ã" "å°‚é–€çš„ã«" ãªã©ï¼‰

### æ¨å®šæ”¹å–„åŠ¹æœ
- **Accuracy**: Â±0 (å¤‰åŒ–ãªã—)
- **Latency**: -0.3-0.5s (å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã«ã‚ˆã‚‹)
- **Cost**: -20-30% (ãƒˆãƒ¼ã‚¯ãƒ³æ•°å‰Šæ¸›ã«ã‚ˆã‚‹)

### å„ªå…ˆåº¦
â­â­â­ (ä¸­) - latency ã¨ cost ã®æ”¹å–„
```


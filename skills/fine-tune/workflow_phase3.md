# Phase 3: åå¾©çš„æ”¹å–„

ãƒ‡ãƒ¼ã‚¿é§†å‹•ã§æ®µéšçš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–ã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã€‚

**æ‰€è¦æ™‚é–“**: å„ iteration 1-2æ™‚é–“ Ã— iterations æ•°ï¼ˆé€šå¸¸ 3-5å›ï¼‰

**ğŸ“‹ é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“](./workflow.md) | [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–](./prompt_optimization.md)

---

## Phase 3: åå¾©çš„æ”¹å–„

### Iteration ã®ã‚µã‚¤ã‚¯ãƒ«

å„ iteration ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š

1. **å„ªå…ˆé †ä½ä»˜ã‘** (Step 7)
2. **æ”¹å–„å®Ÿæ–½** (Step 8)
3. **æ”¹å–„å¾Œè©•ä¾¡** (Step 9)
4. **çµæœæ¯”è¼ƒ** (Step 10)
5. **ç¶™ç¶šåˆ¤æ–­** (Step 11)

### Step 7: å„ªå…ˆé †ä½ä»˜ã‘

**æ±ºå®šåŸºæº–**:
1. **ç›®æ¨™é”æˆã¸ã®å½±éŸ¿åº¦**
2. **æ”¹å–„ã®å®Ÿç¾å¯èƒ½æ€§**
3. **å®Ÿè£…ã‚³ã‚¹ãƒˆ**

**å„ªå…ˆé †ä½ãƒãƒˆãƒªãƒƒã‚¯ã‚¹**:
```markdown
## æ”¹å–„å„ªå…ˆé †ä½ãƒãƒˆãƒªãƒƒã‚¯ã‚¹

| ãƒãƒ¼ãƒ‰ | å½±éŸ¿åº¦ | å®Ÿç¾å¯èƒ½æ€§ | å®Ÿè£…ã‚³ã‚¹ãƒˆ | ç·åˆã‚¹ã‚³ã‚¢ | å„ªå…ˆåº¦ |
|--------|--------|-----------|-----------|----------|--------|
| analyze_intent | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | 14/15 | 1ä½ |
| generate_response | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | 12/15 | 2ä½ |
| retrieve_context | â­â­ | â­â­â­ | â­â­â­ | 8/15 | 3ä½ |

**Iteration 1 ã®å¯¾è±¡**: analyze_intent ãƒãƒ¼ãƒ‰
```

### Step 8: æ”¹å–„å®Ÿæ–½

**æ”¹å–„å‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ** (`src/nodes/analyzer.py`):
```python
# Before
def analyze_intent(state: GraphState) -> GraphState:
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        temperature=1.0
    )

    messages = [
        SystemMessage(content="You are an intent analyzer. Analyze user input."),
        HumanMessage(content=f"Analyze: {state['user_input']}")
    ]

    response = llm.invoke(messages)
    state["intent"] = response.content
    return state
```

**æ”¹å–„å¾Œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**:
```python
# After - Iteration 1
def analyze_intent(state: GraphState) -> GraphState:
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        temperature=0.3  # åˆ†é¡ã‚¿ã‚¹ã‚¯ã«ã¯ä½ã‚ã® temperature
    )

    # æ˜ç¢ºãªåˆ†é¡ã‚«ãƒ†ã‚´ãƒªã¨ few-shot examples
    system_prompt = """You are an intent classifier for a customer support chatbot.

Classify user input into one of these categories:
- "product_inquiry": Questions about products or services
- "technical_support": Technical issues or troubleshooting
- "billing": Payment, invoicing, or billing questions
- "general": General questions or chitchat

Output ONLY a valid JSON object with this structure:
{
  "intent": "<category>",
  "confidence": <0.0-1.0>,
  "reasoning": "<brief explanation>"
}

Examples:

Input: "How much does the premium plan cost?"
Output: {"intent": "product_inquiry", "confidence": 0.95, "reasoning": "Question about product pricing"}

Input: "I can't log into my account"
Output: {"intent": "technical_support", "confidence": 0.9, "reasoning": "Authentication issue"}

Input: "Why was I charged twice?"
Output: {"intent": "billing", "confidence": 0.95, "reasoning": "Question about billing charges"}

Input: "Hello, how are you?"
Output: {"intent": "general", "confidence": 0.85, "reasoning": "General greeting"}

Input: "What's the return policy?"
Output: {"intent": "product_inquiry", "confidence": 0.9, "reasoning": "Question about product policy"}
"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"Input: {state['user_input']}\nOutput:")
    ]

    response = llm.invoke(messages)

    # JSON ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
    try:
        intent_data = json.loads(response.content)
        state["intent"] = intent_data["intent"]
        state["confidence"] = intent_data["confidence"]
    except json.JSONDecodeError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        state["intent"] = "general"
        state["confidence"] = 0.5

    return state
```

**å¤‰æ›´å†…å®¹ã‚µãƒãƒªãƒ¼**:
1. âœ… temperature: 1.0 â†’ 0.3ï¼ˆåˆ†é¡ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸè¨­å®šï¼‰
2. âœ… æ˜ç¢ºãªåˆ†é¡ã‚«ãƒ†ã‚´ãƒªï¼ˆ4ã¤ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆï¼‰
3. âœ… Few-shot examplesï¼ˆ5å€‹è¿½åŠ ï¼‰
4. âœ… JSON å‡ºåŠ›å½¢å¼ï¼ˆæ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ï¼‰
5. âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆJSON ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

### Step 9: æ”¹å–„å¾Œè©•ä¾¡

**å®Ÿè¡Œ**:
```bash
# æ”¹å–„å¾Œã®è©•ä¾¡ã‚’åŒã˜æ¡ä»¶ã§å®Ÿè¡Œ
./evaluation_after_iteration1.sh
```

### Step 10: çµæœæ¯”è¼ƒ

**æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä¾‹**:
```markdown
# Iteration 1 è©•ä¾¡çµæœ

å®Ÿè¡Œæ—¥æ™‚: 2024-11-24 12:00:00
å¤‰æ›´å†…å®¹: analyze_intent ãƒãƒ¼ãƒ‰ã®æœ€é©åŒ–

## çµæœæ¯”è¼ƒ

| æŒ‡æ¨™ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | Iteration 1 | å¤‰åŒ– | å¤‰åŒ–ç‡ | ç›®æ¨™ | é”æˆç‡ |
|------|-------------|-------------|------|--------|------|--------|
| **Accuracy** | 75.0% | **86.0%** | **+11.0%** | +14.7% | 90.0% | 95.6% |
| **Latency** | 2.5s | 2.4s | -0.1s | -4.0% | 2.0s | 80.0% |
| **Cost/req** | $0.015 | $0.014 | -$0.001 | -6.7% | $0.010 | 71.4% |

## è©³ç´°åˆ†æ

### Accuracy ã®æ”¹å–„
- **å‘ä¸Š**: +11.0% (75.0% â†’ 86.0%)
- **æ®‹ã‚Šã‚®ãƒ£ãƒƒãƒ—**: 4.0% (ç›®æ¨™90.0%)
- **æ”¹å–„ã§ããŸã‚±ãƒ¼ã‚¹**: ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆåˆ†é¡ãƒŸã‚¹ãŒ 12 â†’ 3 ã‚±ãƒ¼ã‚¹ã«æ¸›å°‘
- **ã¾ã æ”¹å–„ãŒå¿…è¦**: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ä¸è¶³ã®ã‚±ãƒ¼ã‚¹ï¼ˆ5ã‚±ãƒ¼ã‚¹ï¼‰

### Latency ã®è‹¥å¹²æ”¹å–„
- **å‘ä¸Š**: -0.1s (2.5s â†’ 2.4s)
- **ä¸»ãªè¦å› **: analyze_intent ã®æ¸©åº¦ä¸‹é™ã«ã‚ˆã‚Šå‡ºåŠ›ãŒç°¡æ½”ã«ãªã£ãŸ
- **æ®‹ã‚Šãƒœãƒˆãƒ«ãƒãƒƒã‚¯**: generate_response (å¹³å‡ 1.8s)

### Cost ã®è‹¥å¹²å‰Šæ¸›
- **å‰Šæ¸›**: -$0.001 (6.7%å‰Šæ¸›)
- **è¦å› **: analyze_intent ã®å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›
- **ä¸»ãªã‚³ã‚¹ãƒˆ**: generate_response ãŒä¾ç„¶ã¨ã—ã¦73%ã‚’å ã‚ã‚‹

## æ¬¡ã® Iteration ã®æ–¹é‡

### å„ªå…ˆåº¦1: generate_response ã®æœ€é©åŒ–
- **ç›®æ¨™**: Latency ã‚’ 1.8s â†’ 1.4sã€Cost ã‚’ $0.011 â†’ $0.007
- **ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:
  1. ç°¡æ½”æ€§ã®æŒ‡ç¤ºè¿½åŠ 
  2. max_tokens ã‚’ 500 ã«åˆ¶é™
  3. temperature ã‚’ 0.7 â†’ 0.5 ã«èª¿æ•´

### å„ªå…ˆåº¦2: Accuracy ã®æœ€å¾Œã®4%å‘ä¸Š
- **ç›®æ¨™**: 86.0% â†’ 90.0%ä»¥ä¸Š
- **ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã‚’æ”¹å–„ï¼ˆretrieve_context ãƒãƒ¼ãƒ‰ï¼‰

## åˆ¤å®š
âœ… ç¶™ç¶š â†’ Iteration 2 ã«é€²ã‚€
```

### Step 11: ç¶™ç¶šåˆ¤æ–­

**åˆ¤æ–­åŸºæº–**:
```python
def should_continue_iteration(results: Dict, goals: Dict) -> bool:
    """Iteration ã‚’ç¶™ç¶šã™ã¹ãã‹åˆ¤æ–­"""
    all_goals_met = True

    for metric, goal in goals.items():
        if metric == "accuracy":
            if results[metric] < goal:
                all_goals_met = False
        elif metric in ["latency", "cost"]:
            if results[metric] > goal:
                all_goals_met = False

    return not all_goals_met

# ä¾‹
goals = {"accuracy": 90.0, "latency": 2.0, "cost": 0.010}
results = {"accuracy": 86.0, "latency": 2.4, "cost": 0.014}

if should_continue_iteration(results, goals):
    print("æ¬¡ã® Iteration ã«é€²ã‚€")
else:
    print("ç›®æ¨™é”æˆ - Phase 4 ã¸")
```

**Iteration ã®ä¸Šé™**:
- **æ¨å¥¨**: 3-5 iterations
- **ç†ç”±**: ãã‚Œä»¥ä¸Šã¯åç›Šé€“æ¸›ã®æ³•å‰‡ãŒåƒãå¯èƒ½æ€§ãŒé«˜ã„
- **ä¾‹å¤–**: Critical ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ 10+ iterations ã‚‚å¯

